{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68873e20-f584-4efc-a4c2-37f930910de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\inwej\\anaconda3\\Lib\\tkinter\\__init__.py\", line 1948, in __call__\n",
      "    return self.func(*args)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\inwej\\AppData\\Local\\Temp\\ipykernel_18812\\600608821.py\", line 187, in <lambda>\n",
      "    operation_button = Button(operation_window, text=\"Proceed\", style=\"Green.TButton\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
      "                                                                                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\inwej\\AppData\\Local\\Temp\\ipykernel_18812\\600608821.py\", line 201, in perform_operation\n",
      "    detect_objects(video_path)\n",
      "  File \"C:\\Users\\inwej\\AppData\\Local\\Temp\\ipykernel_18812\\600608821.py\", line 22, in detect_objects\n",
      "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "cv2.error: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\dnn\\src\\darknet\\darknet_importer.cpp:210: error: (-212:Parsing error) Failed to open NetParameter file: cfg/yolov3.cfg in function 'cv::dnn::dnn4_v20231225::readNetFromDarknet'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from tkinter.ttk import Style, Button, Label, Entry, Radiobutton\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects(video_path):\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise in the video\n",
    "def reduce_noise(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_image = cv2.medianBlur(frame, 15)\n",
    "        cv2.imshow('Video with Reduced Noise', filtered_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen the video\n",
    "def sharpen_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_image = cv2.filter2D(frame, -1, kernel)\n",
    "        cv2.imshow('Sharpened Video', sharpened_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast of the video\n",
    "def adjust_brightness_contrast(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        brightness = 5\n",
    "        contrast = 1.5\n",
    "        adjusted_image = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        cv2.imshow('Video with Adjusted Brightness and Contrast', adjusted_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    \n",
    "    # Create a new Toplevel window for welcome message\n",
    "    welcome_window = tk.Toplevel()\n",
    "    welcome_window.title(\"Welcome\")\n",
    "    \n",
    "    # Create a Label with formatted text\n",
    "    welcome_text = (\n",
    "        f\"Hello {name}.\\n\\n\"\n",
    "        f\"Welcome to NWEJ's Video Editing and Detection Suite.\\n\\n\"\n",
    "        \"This is an application that allows you to perform various operations on a video.\\n\\n\"\n",
    "        \"Such operations include sharpening images, object detection, adjusting brightness and contrast etc.\"\n",
    "    )\n",
    "    label = tk.Label(welcome_window, text=welcome_text, font=(\"Arial\", 12, \"bold\"), justify=\"center\")\n",
    "    label.pack(padx=20, pady=20)\n",
    "    \n",
    "    # Destroy the welcome window after a delay\n",
    "    welcome_window.after(12000, welcome_window.destroy)\n",
    "    \n",
    "    # Close the home_window after the welcome message is displayed\n",
    "    home_window.withdraw()\n",
    "    \n",
    "    # Create the operation window\n",
    "    operation_window = tk.Toplevel()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "    operation_window.geometry(\"400x300\")\n",
    "\n",
    "    # Style\n",
    "    style = Style()\n",
    "    style.configure(\"Green.TButton\", foreground=\"black\", background=\"green\")\n",
    "    style.configure(\"Red.TButton\", foreground=\"black\", background=\"red\")\n",
    "    \n",
    "    # Label\n",
    "    operation_label = Label(operation_window, text=f\"Select an operation you would like to perform:\\n\\n\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    # Radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    operation_var.set(1)  # Default selection\n",
    "    operations = [(\"Watch Video Normally\", 1), (\"Perform Object Detection\", 2), (\"Reduce Noise\", 3), (\"Sharpen Video\", 4), (\"Adjust Brightness and Contrast\", 5)]\n",
    "    for text, value in operations:\n",
    "        Radiobutton(operation_window, text=text, variable=operation_var, value=value).pack(anchor='w')\n",
    "\n",
    "    information_label = Label(operation_window, text=f\"\\nYou will be redirected to another window to select a video for your selected operation.\\n\\n\")\n",
    "    information_label.pack()\n",
    "\n",
    "    quit_label= Label(operation_window, text=f\"You can press 'Q'to end the video at any time.\\n\\n\")\n",
    "    quit_label.pack()\n",
    "\n",
    "    # Button\n",
    "    operation_button = Button(operation_window, text=\"Proceed\", style=\"Green.TButton\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        if operation == 1:\n",
    "            play_video(video_path)\n",
    "        elif operation == 2:\n",
    "            detect_objects(video_path)\n",
    "        elif operation == 3:\n",
    "            reduce_noise(video_path)\n",
    "        elif operation == 4:\n",
    "            sharpen_video(video_path)\n",
    "        elif operation == 5:\n",
    "            adjust_brightness_contrast(video_path)\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = Entry(home_window)\n",
    "button_start = Button(home_window, text=\"Start\", style=\"Green.TButton\", command=operation_window)\n",
    "button_reset = Button(home_window, text=\"Reset\", style=\"Red.TButton\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c3c7d4-41e3-470f-9a57-a95724e39f1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b53f412-1573-4727-b269-b59b7646b4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
