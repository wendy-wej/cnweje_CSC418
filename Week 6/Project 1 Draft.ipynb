{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b125e9a5-696a-409a-a642-1f285ab53e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load YOLO\n",
    "net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "classes = []\n",
    "with open('cfg/coco.names', 'r') as f:\n",
    "    classes = f.read().splitlines()\n",
    "\n",
    "# Load input video\n",
    "video = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "\n",
    "# Get video properties\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess input frame\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "    #blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "\n",
    "    # Forward pass through the network\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "    # Process detection results\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_outputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "    # Non-max suppression to remove redundant overlapping boxes\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "    # Draw bounding boxes and labels\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten():\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i], 2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "    # Write the frame with detected objects to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # Press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release video capture and writer objects\n",
    "video.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ee2334-30e2-43eb-9004-043c930efc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODEE !!\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects():\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "        #blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    messagebox.showinfo(\"Welcome\", f\"Welcome {name}. \\nThis application allows you to perform object detection on a video.\")\n",
    "    home_window.destroy()\n",
    "    \n",
    "    operation_window = tk.Tk()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "\n",
    "    #label\n",
    "    operation_label = tk.Label(operation_window, text=\"Select Operation an operation you would like to perform:\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    #radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    tk.Radiobutton(operation_window, text=\"Watch Video\", variable=operation_var, value=1).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Perform Object Detection\", variable=operation_var, value=2).pack()\n",
    "    video_label = tk.Label(operation_window, text=\"You can press Q to stop the video at any time\")\n",
    "\n",
    "    #Button\n",
    "    operation_button = tk.Button(operation_window, text=\"Proceed\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation == 1:\n",
    "        play_video()\n",
    "    else:\n",
    "       detect_objects()\n",
    "\n",
    "        \n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = tk.Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = tk.Entry(home_window)\n",
    "button_start = tk.Button(home_window, text=\"Start\", command=operation_window)\n",
    "button_reset = tk.Button(home_window, text=\"Reset\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862bcca0-2108-4bd4-88d3-7a2b63cc2092",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First draft with multiple operations\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects():\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise in the video\n",
    "def reduce_noise():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    out_path = 'output_videos/reduced_noise_video.avi'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, 20.0, (640, 480))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_frame = cv2.medianBlur(frame, 15)  # Apply median blur\n",
    "        out.write(filtered_frame)\n",
    "        cv2.imshow('Reduced Noise Video', filtered_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen the video\n",
    "def sharpen_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    out_path = 'output_videos/sharpened_video.avi'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, 20.0, (640, 480))\n",
    "\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # Sharpening kernel\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        sharpened_frame = cv2.filter2D(frame, -1, kernel)  # Apply sharpening\n",
    "        out.write(sharpened_frame)\n",
    "        cv2.imshow('Sharpened Video', sharpened_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast in the video\n",
    "def adjust_brightness_contrast():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    out_path = 'output_videos/adjusted_video.avi'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(out_path, fourcc, 20.0, (640, 480))\n",
    "\n",
    "    brightness = 5\n",
    "    contrast = 1.5\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        adjusted_frame = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        out.write(adjusted_frame)\n",
    "        cv2.imshow('Adjusted Video', adjusted_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    messagebox.showinfo(\"Welcome\", f\"Welcome {name}. \\nThis application allows you to perform various operations on a video.\")\n",
    "    home_window.destroy()\n",
    "    \n",
    "    operation_window = tk.Tk()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "\n",
    "    # Label\n",
    "    operation_label = tk.Label(operation_window, text=\"Select an operation you would like to perform:\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    # Radio buttons for operations\n",
    "    tk.Radiobutton(operation_window, text=\"Watch Video\", variable=operation_var, value=1).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Perform Object Detection\", variable=operation_var, value=2).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Reduce Noise\", variable=operation_var, value=3).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Sharpen Video\", variable=operation_var, value=4).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Adjust Brightness and Contrast\", variable=operation_var, value=5).pack()\n",
    "    \n",
    "    # Button\n",
    "    operation_button = tk.Button(operation_window, text=\"Proceed\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation == 1:\n",
    "        play_video()\n",
    "    elif operation == 2:\n",
    "       detect_objects()\n",
    "    elif operation == 3:\n",
    "        reduce_noise()\n",
    "    elif operation == 4:\n",
    "        sharpen_video()\n",
    "    elif operation == 5:\n",
    "        adjust_brightness_contrast()\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = tk.Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = tk.Entry(home_window)\n",
    "button_start = tk.Button(home_window, text=\"Start\", command=operation_window)\n",
    "button_reset = tk.Button(home_window, text=\"Reset\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Variable to store operation choice\n",
    "operation_var = tk.IntVar()\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6be6a746-2b1d-49da-8087-4b6745e5a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Good draft with all the operations\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects():\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * frame.shape[1])\n",
    "                    center_y = int(detection[1] * frame.shape[0])\n",
    "                    w = int(detection[2] * frame.shape[1])\n",
    "                    h = int(detection[3] * frame.shape[0])\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise on video\n",
    "def reduce_noise():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_frame = cv2.medianBlur(frame, 15)  # Apply median blur\n",
    "        cv2.imshow('Reduced Noise Video', filtered_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen video\n",
    "def sharpen_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])  # Sharpening kernel\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        sharpened_frame = cv2.filter2D(frame, -1, kernel)  # Apply sharpening\n",
    "        cv2.imshow('Sharpened Video', sharpened_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast on video\n",
    "def adjust_brightness_contrast():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    brightness = 5\n",
    "    contrast = 1.5\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        adjusted_frame = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        cv2.imshow('Adjusted Video', adjusted_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    messagebox.showinfo(\"Welcome\", f\"Welcome {name}. \\nThis application allows you to perform various operations on a video.\")\n",
    "    home_window.destroy()\n",
    "    \n",
    "    operation_window = tk.Tk()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "\n",
    "    #label\n",
    "    operation_label = tk.Label(operation_window, text=\"Select an operation you would like to perform:\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    #radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    tk.Radiobutton(operation_window, text=\"Watch Video Normally\", variable=operation_var, value=1).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Perform Object Detection\", variable=operation_var, value=2).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Reduce Noise\", variable=operation_var, value=3).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Sharpen Video\", variable=operation_var, value=4).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Adjust Brightness and Contrast\", variable=operation_var, value=5).pack()\n",
    "\n",
    "    #Button\n",
    "    operation_button = tk.Button(operation_window, text=\"Proceed\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation == 1:\n",
    "        play_video()\n",
    "    elif operation == 2:\n",
    "        detect_objects()\n",
    "    elif operation == 3:\n",
    "        reduce_noise()\n",
    "    elif operation == 4:\n",
    "        sharpen_video()\n",
    "    elif operation == 5:\n",
    "        adjust_brightness_contrast()\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = tk.Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = tk.Entry(home_window)\n",
    "button_start = tk.Button(home_window, text=\"Start\", command=operation_window)\n",
    "button_reset = tk.Button(home_window, text=\"Reset\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c570028-d0f4-47a5-b0be-564bc8529bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects():\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise in the video\n",
    "def reduce_noise():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_image = cv2.medianBlur(frame, 15)\n",
    "        cv2.imshow('Video with Reduced Noise', filtered_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen the video\n",
    "def sharpen_video():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_image = cv2.filter2D(frame, -1, kernel)\n",
    "        cv2.imshow('Sharpened Video', sharpened_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast of the video\n",
    "def adjust_brightness_contrast():\n",
    "    cap = cv2.VideoCapture('videos/sst_foyer_1.mp4')\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        brightness = 5\n",
    "        contrast = 1.5\n",
    "        adjusted_image = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        cv2.imshow('Video with Adjusted Brightness and Contrast', adjusted_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    messagebox.showinfo(\"Welcome\", f\"Welcome {name}. This application allows you to perform various operations on a video.\")\n",
    "    home_window.destroy()\n",
    "    \n",
    "    operation_window = tk.Tk()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "\n",
    "    #label\n",
    "    operation_label = tk.Label(operation_window, text=\"Select an operation you would like to perform:\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    #radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    tk.Radiobutton(operation_window, text=\"Watch Video Normally\", variable=operation_var, value=1).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Perform Object Detection\", variable=operation_var, value=2).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Reduce Noise\", variable=operation_var, value=3).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Sharpen Video\", variable=operation_var, value=4).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Adjust Brightness and Contrast\", variable=operation_var, value=5).pack()\n",
    "\n",
    "    #Button\n",
    "    operation_button = tk.Button(operation_window, text=\"Proceed\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation == 1:\n",
    "        play_video()\n",
    "    elif operation == 2:\n",
    "        detect_objects()\n",
    "    elif operation == 3:\n",
    "        reduce_noise()\n",
    "    elif operation == 4:\n",
    "        sharpen_video()\n",
    "    elif operation == 5:\n",
    "        adjust_brightness_contrast()\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = tk.Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = tk.Entry(home_window)\n",
    "button_start = tk.Button(home_window, text=\"Start\", command=operation_window)\n",
    "button_reset = tk.Button(home_window, text=\"Reset\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f45b2a4d-f414-4499-a5ba-a52f31a6801f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects(video_path):\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise in the video\n",
    "def reduce_noise(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_image = cv2.medianBlur(frame, 15)\n",
    "        cv2.imshow('Video with Reduced Noise', filtered_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen the video\n",
    "def sharpen_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_image = cv2.filter2D(frame, -1, kernel)\n",
    "        cv2.imshow('Sharpened Video', sharpened_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast of the video\n",
    "def adjust_brightness_contrast(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        brightness = 5\n",
    "        contrast = 1.5\n",
    "        adjusted_image = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        cv2.imshow('Video with Adjusted Brightness and Contrast', adjusted_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    messagebox.showinfo(\"Welcome\", f\"Welcome {name}. This application allows you to perform various operations on a video.\")\n",
    "    home_window.destroy()\n",
    "    \n",
    "    operation_window = tk.Tk()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "\n",
    "    #label\n",
    "    operation_label = tk.Label(operation_window, text=\"Select an operation you would like to perform:\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    #radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    tk.Radiobutton(operation_window, text=\"Watch Video Normally\", variable=operation_var, value=1).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Perform Object Detection\", variable=operation_var, value=2).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Reduce Noise\", variable=operation_var, value=3).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Sharpen Video\", variable=operation_var, value=4).pack()\n",
    "    tk.Radiobutton(operation_window, text=\"Adjust Brightness and Contrast\", variable=operation_var, value=5).pack()\n",
    "    information_label = tk.Label(operation_window, text=\"You will be redirected to another window to select a video for your selected operation.\")\n",
    "    information_label.pack()\n",
    "\n",
    "    #Button\n",
    "    operation_button = tk.Button(operation_window, text=\"Proceed\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation == 1:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        play_video(video_path)\n",
    "    elif operation == 2:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        detect_objects(video_path)\n",
    "    elif operation == 3:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        reduce_noise(video_path)\n",
    "    elif operation == 4:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        sharpen_video(video_path)\n",
    "    elif operation == 5:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        adjust_brightness_contrast(video_path)\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = tk.Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = tk.Entry(home_window)\n",
    "button_start = tk.Button(home_window, text=\"Start\", command=operation_window)\n",
    "button_reset = tk.Button(home_window, text=\"Reset\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81452b4-af99-436d-a59c-b427009e6ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox, filedialog\n",
    "from tkinter.ttk import Style, Button, Label, Entry, Radiobutton\n",
    "\n",
    "# Function to play video normally\n",
    "def play_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        cv2.imshow('Video', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform object detection on video\n",
    "def detect_objects(video_path):\n",
    "    net = cv2.dnn.readNet('cfg/yolov3.weights', 'cfg/yolov3.cfg')\n",
    "    classes = []\n",
    "    with open('cfg/coco.names', 'r') as f:\n",
    "        classes = f.read().splitlines()\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter('output_video.avi', fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        blob = cv2.dnn.blobFromImage(frame, 1/255.0, (224, 224), swapRB=True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layer_outputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layer_outputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_PLAIN\n",
    "        colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "        if len(indexes) > 0:\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = str(round(confidences[i], 2))\n",
    "                color = colors[i]\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "                cv2.putText(frame, label + \" \" + confidence, (x, y + 20), font, 2, (255, 255, 255), 2)\n",
    "\n",
    "        out.write(frame)\n",
    "        cv2.imshow('Video with Object Detection', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to reduce noise in the video\n",
    "def reduce_noise(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        filtered_image = cv2.medianBlur(frame, 15)\n",
    "        cv2.imshow('Video with Reduced Noise', filtered_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to sharpen the video\n",
    "def sharpen_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "        sharpened_image = cv2.filter2D(frame, -1, kernel)\n",
    "        cv2.imshow('Sharpened Video', sharpened_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to adjust brightness and contrast of the video\n",
    "def adjust_brightness_contrast(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        brightness = 5\n",
    "        contrast = 1.5\n",
    "        adjusted_image = cv2.addWeighted(frame, contrast, np.zeros(frame.shape, frame.dtype), 0, brightness)\n",
    "        cv2.imshow('Video with Adjusted Brightness and Contrast', adjusted_image)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "# Function to perform operations based on user choice\n",
    "def operation_window():\n",
    "    name = entry_name.get()\n",
    "    \n",
    "    # Create a new Toplevel window for welcome message\n",
    "    welcome_window = tk.Toplevel()\n",
    "    welcome_window.title(\"Welcome\")\n",
    "    \n",
    "    # Create a Label with formatted text\n",
    "    welcome_text = (\n",
    "        f\"Hello {name}.\\n\\n\"\n",
    "        f\"Welcome to NWEJ's Video Editing and Detection Suite.\\n\\n\"\n",
    "        \"This is an application that allows you to perform various operations on a video.\\n\\n\"\n",
    "        \"Such operations include sharpening images, object detection, adjusting brightness and contrast etc.\"\n",
    "    )\n",
    "    label = tk.Label(welcome_window, text=welcome_text, font=(\"Arial\", 12, \"bold\"), justify=\"center\")\n",
    "    label.pack(padx=20, pady=20)\n",
    "    \n",
    "    # Destroy the welcome window after a delay\n",
    "    welcome_window.after(12000, welcome_window.destroy)\n",
    "    \n",
    "    # Close the home_window after the welcome message is displayed\n",
    "    home_window.withdraw()\n",
    "    \n",
    "    # Create the operation window\n",
    "    operation_window = tk.Toplevel()   \n",
    "    operation_window.title(\"Choose Operation\")\n",
    "    operation_window.geometry(\"400x300\")\n",
    "\n",
    "    # Style\n",
    "    style = Style()\n",
    "    style.configure(\"Green.TButton\", foreground=\"black\", background=\"green\")\n",
    "    style.configure(\"Red.TButton\", foreground=\"black\", background=\"red\")\n",
    "    \n",
    "    # Label\n",
    "    operation_label = Label(operation_window, text=f\"Select an operation you would like to perform:\\n\\n\")\n",
    "    operation_label.pack()\n",
    "\n",
    "    # Radio button\n",
    "    operation_var = tk.IntVar()\n",
    "    operation_var.set(1)  # Default selection\n",
    "    operations = [(\"Watch Video Normally\", 1), (\"Perform Object Detection\", 2), (\"Reduce Noise\", 3), (\"Sharpen Video\", 4), (\"Adjust Brightness and Contrast\", 5)]\n",
    "    for text, value in operations:\n",
    "        Radiobutton(operation_window, text=text, variable=operation_var, value=value).pack(anchor='w')\n",
    "\n",
    "    information_label = Label(operation_window, text=f\"You will be redirected to another window to select a video for your selected operation.\\n\\n\")\n",
    "    information_label.pack()\n",
    "\n",
    "    # Button\n",
    "    operation_button = Button(operation_window, text=\"Proceed\", style=\"Green.TButton\", command=lambda: perform_operation(operation_var.get(), operation_window))\n",
    "    operation_button.pack()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def perform_operation(operation, operation_window):\n",
    "    operation_window.destroy()\n",
    "    if operation:\n",
    "        video_path = filedialog.askopenfilename(title=\"Select Video\", filetypes=[(\"Video files\", \"*.mp4;*.avi\")])\n",
    "        if operation == 1:\n",
    "            play_video(video_path)\n",
    "        elif operation == 2:\n",
    "            detect_objects(video_path)\n",
    "        elif operation == 3:\n",
    "            reduce_noise(video_path)\n",
    "        elif operation == 4:\n",
    "            sharpen_video(video_path)\n",
    "        elif operation == 5:\n",
    "            adjust_brightness_contrast(video_path)\n",
    "\n",
    "# Function to reset the application\n",
    "def reset():\n",
    "    entry_name.delete(0, tk.END)\n",
    "    messagebox.showinfo(\"Reset\", \"Application has been reset.\")\n",
    "\n",
    "# Create tkinter home_window\n",
    "home_window = tk.Tk()\n",
    "home_window.title(\"Video Processing Application\")\n",
    "\n",
    "# Create widgets\n",
    "label_name = Label(home_window, text=\"Enter your name:\")\n",
    "entry_name = Entry(home_window)\n",
    "button_start = Button(home_window, text=\"Start\", style=\"Green.TButton\", command=operation_window)\n",
    "button_reset = Button(home_window, text=\"Reset\", style=\"Red.TButton\", command=reset)\n",
    "\n",
    "# Place widgets in the home_window\n",
    "label_name.grid(row=0, column=0, padx=10, pady=5)\n",
    "entry_name.grid(row=0, column=1, padx=10, pady=5)\n",
    "button_start.grid(row=1, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "button_reset.grid(row=2, column=0, columnspan=2, padx=10, pady=5, sticky=\"WE\")\n",
    "\n",
    "# Run the tkinter event loop\n",
    "home_window.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfac0cb-5745-4018-bb82-3d51e628bdac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
